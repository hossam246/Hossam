{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Churn Prediction Jupyter Notebook\n",
    "\n",
    "# Step 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load Datasets\n",
    "train_data = pd.read_csv(\"customer_churn_dataset-training-master.csv\")\n",
    "test_data = pd.read_csv(\"customer_churn_dataset-testing-master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Head:\n",
      "   CustomerID   Age  Gender  Tenure  Usage Frequency  Support Calls  \\\n",
      "0         2.0  30.0  Female    39.0             14.0            5.0   \n",
      "1         3.0  65.0  Female    49.0              1.0           10.0   \n",
      "2         4.0  55.0  Female    14.0              4.0            6.0   \n",
      "3         5.0  58.0    Male    38.0             21.0            7.0   \n",
      "4         6.0  23.0    Male    32.0             20.0            5.0   \n",
      "\n",
      "   Payment Delay Subscription Type Contract Length  Total Spend  \\\n",
      "0           18.0          Standard          Annual        932.0   \n",
      "1            8.0             Basic         Monthly        557.0   \n",
      "2           18.0             Basic       Quarterly        185.0   \n",
      "3            7.0          Standard         Monthly        396.0   \n",
      "4            8.0             Basic         Monthly        617.0   \n",
      "\n",
      "   Last Interaction  Churn  \n",
      "0              17.0    1.0  \n",
      "1               6.0    1.0  \n",
      "2               3.0    1.0  \n",
      "3              29.0    1.0  \n",
      "4              20.0    1.0  \n",
      "\n",
      "Training Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 440833 entries, 0 to 440832\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   CustomerID         440832 non-null  float64\n",
      " 1   Age                440832 non-null  float64\n",
      " 2   Gender             440832 non-null  object \n",
      " 3   Tenure             440832 non-null  float64\n",
      " 4   Usage Frequency    440832 non-null  float64\n",
      " 5   Support Calls      440832 non-null  float64\n",
      " 6   Payment Delay      440832 non-null  float64\n",
      " 7   Subscription Type  440832 non-null  object \n",
      " 8   Contract Length    440832 non-null  object \n",
      " 9   Total Spend        440832 non-null  float64\n",
      " 10  Last Interaction   440832 non-null  float64\n",
      " 11  Churn              440832 non-null  float64\n",
      "dtypes: float64(9), object(3)\n",
      "memory usage: 40.4+ MB\n",
      "None\n",
      "\n",
      "Testing Data Head:\n",
      "   CustomerID  Age  Gender  Tenure  Usage Frequency  Support Calls  \\\n",
      "0           1   22  Female      25               14              4   \n",
      "1           2   41  Female      28               28              7   \n",
      "2           3   47    Male      27               10              2   \n",
      "3           4   35    Male       9               12              5   \n",
      "4           5   53  Female      58               24              9   \n",
      "\n",
      "   Payment Delay Subscription Type Contract Length  Total Spend  \\\n",
      "0             27             Basic         Monthly          598   \n",
      "1             13          Standard         Monthly          584   \n",
      "2             29           Premium          Annual          757   \n",
      "3             17           Premium       Quarterly          232   \n",
      "4              2          Standard          Annual          533   \n",
      "\n",
      "   Last Interaction  Churn  \n",
      "0                 9      1  \n",
      "1                20      0  \n",
      "2                21      0  \n",
      "3                18      0  \n",
      "4                18      0  \n",
      "\n",
      "Testing Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64374 entries, 0 to 64373\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   CustomerID         64374 non-null  int64 \n",
      " 1   Age                64374 non-null  int64 \n",
      " 2   Gender             64374 non-null  object\n",
      " 3   Tenure             64374 non-null  int64 \n",
      " 4   Usage Frequency    64374 non-null  int64 \n",
      " 5   Support Calls      64374 non-null  int64 \n",
      " 6   Payment Delay      64374 non-null  int64 \n",
      " 7   Subscription Type  64374 non-null  object\n",
      " 8   Contract Length    64374 non-null  object\n",
      " 9   Total Spend        64374 non-null  int64 \n",
      " 10  Last Interaction   64374 non-null  int64 \n",
      " 11  Churn              64374 non-null  int64 \n",
      "dtypes: int64(9), object(3)\n",
      "memory usage: 5.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Explore the Datasets\n",
    "print(\"Training Data Head:\")\n",
    "print(train_data.head())\n",
    "print(\"\\nTraining Data Info:\")\n",
    "print(train_data.info())\n",
    "print(\"\\nTesting Data Head:\")\n",
    "print(test_data.head())\n",
    "print(\"\\nTesting Data Info:\")\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in Training Data:\n",
      "CustomerID           1\n",
      "Age                  1\n",
      "Gender               1\n",
      "Tenure               1\n",
      "Usage Frequency      1\n",
      "Support Calls        1\n",
      "Payment Delay        1\n",
      "Subscription Type    1\n",
      "Contract Length      1\n",
      "Total Spend          1\n",
      "Last Interaction     1\n",
      "Churn                1\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Testing Data:\n",
      "CustomerID           0\n",
      "Age                  0\n",
      "Gender               0\n",
      "Tenure               0\n",
      "Usage Frequency      0\n",
      "Support Calls        0\n",
      "Payment Delay        0\n",
      "Subscription Type    0\n",
      "Contract Length      0\n",
      "Total Spend          0\n",
      "Last Interaction     0\n",
      "Churn                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Check for Missing Values\n",
    "print(\"\\nMissing Values in Training Data:\")\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Values in Testing Data:\")\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Handle Missing Values (if any)\n",
    "# Fill missing numerical values with the median and categorical values with the mode\n",
    "for column in train_data.columns:\n",
    "    if train_data[column].dtype == 'object':\n",
    "        train_data[column].fillna(train_data[column].mode()[0], inplace=True)\n",
    "    else:\n",
    "        train_data[column].fillna(train_data[column].median(), inplace=True)\n",
    "\n",
    "for column in test_data.columns:\n",
    "    if test_data[column].dtype == 'object':\n",
    "        test_data[column].fillna(test_data[column].mode()[0], inplace=True)\n",
    "    else:\n",
    "        test_data[column].fillna(test_data[column].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Encode Categorical Variables\n",
    "label_encoders = {}\n",
    "for column in train_data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    train_data[column] = le.fit_transform(train_data[column])\n",
    "    test_data[column] = le.transform(test_data[column])\n",
    "    label_encoders[column] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Separate Features and Target\n",
    "X_train = train_data.drop(columns=['Churn'])\n",
    "y_train = train_data['Churn']\n",
    "\n",
    "X_test = test_data.drop(columns=['Churn'])\n",
    "y_test = test_data['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Handle Class Imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Scale Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest...\n"
     ]
    }
   ],
   "source": [
    "# Step 10.1: Train and Evaluate Random Forest\n",
    "print(\"\\nTraining Random Forest...\")\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train_resampled)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10.2: Train and Evaluate Logistic Regression\n",
    "print(\"\\nTraining Logistic Regression...\")\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train_resampled)\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "precision_lr = precision_score(y_test, y_pred_lr)\n",
    "recall_lr = recall_score(y_test, y_pred_lr)\n",
    "print(\"\\nLogistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10.3: Train and Evaluate Decision Tree Classifier\n",
    "print(\"\\nTraining Decision Tree Classifier...\")\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_scaled, y_train_resampled)\n",
    "y_pred_dt = dt_model.predict(X_test_scaled)\n",
    "\n",
    "precision_dt = precision_score(y_test, y_pred_dt)\n",
    "recall_dt = recall_score(y_test, y_pred_dt)\n",
    "print(\"\\nDecision Tree Classifier Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Results Summary\n",
    "results = [\n",
    "    {\"Model\": \"Random Forest\", \"Precision\": precision_rf, \"Recall\": recall_rf},\n",
    "    {\"Model\": \"Logistic Regression\", \"Precision\": precision_lr, \"Recall\": recall_lr},\n",
    "    {\"Model\": \"Decision Tree Classifier\", \"Precision\": precision_dt, \"Recall\": recall_dt}\n",
    "]\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Best Model Evaluation\n",
    "best_model_name = max(results, key=lambda x: x['Recall'])['Model']\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "\n",
    "if best_model_name == \"Random Forest\":\n",
    "    final_model = rf_model\n",
    "    y_pred_best = y_pred_rf\n",
    "elif best_model_name == \"Logistic Regression\":\n",
    "    final_model = lr_model\n",
    "    y_pred_best = y_pred_lr\n",
    "else:\n",
    "    final_model = dt_model\n",
    "    y_pred_best = y_pred_dt\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_best), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f'Confusion Matrix ({best_model_name})')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Save the Outputs\n",
    "test_data['Predicted_Churn'] = y_pred_best\n",
    "test_data.to_csv(\"test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Save Metrics Summary\n",
    "results_df.to_csv(\"model_performance_summary.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
